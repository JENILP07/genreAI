# Backend Run Guide - Music Genre Prediction

This guide provides instructions on how to run the FastAPI backend.

## Option 1: Running with Python (Local Development)

1. Navigate to the backend directory:
   cd backend

2. Create a virtual environment:
   python -m venv venv

3. Activate the virtual environment:
   - Linux/macOS: source venv/bin/activate
   - Windows: venv\Scripts\activate

4. Install dependencies:
   pip install -r requirements.txt

5. Start the server:
   uvicorn main:app --reload --host 0.0.0.0 --port 8000

The API will be available at: http://localhost:8000
Documentation (Swagger UI): http://localhost:8000/docs

---

## Option 2: Running with Docker (Recommended for Production)

1. Navigate to the backend directory:
   cd backend

2. Build the Docker image:
   docker build -t genre-genius-backend .

3. Run the container:
   docker run -p 8000:8000 genre-genius-backend

The API will be available at: http://localhost:8000

---

## Notes
- Ensure your ML models are present in the `backend/models/` directory.
- The backend expects audio files via POST requests to `/predict`.
- Maximum file size is limited to 10MB.
